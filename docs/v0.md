# Baseline: `v0`

Let's start implementing a Rust version of the initial, [baseline solution](/src/cpp/v0_baseline/step.hpp).
One notable restriction we must consider are the strict constraints Rust places on memory correctness.
This is not such a big deal for a single-threaded solution, but will be of significant importance when parallelizing our implementation.
Even if we would carefully analyze our code to make sure all threads are writing to distinct indexes in the result memory, Rust will not allow us to launch concurrent threads that contain mutable references to some shared piece of memory, in our case the slice `r`.
We will solve this by first partitioning the result memory into non-overlapping, mutable subslices, and then mapping a function over all subslices.
Since all computations are independent of each other, this approach parallelizes nicely using the work-stealing idiom.

## Serial version

Let's start by implementing the serial version of the algorithm.
Recall how we defined the C API function [`step`](intro.md#calling-rust-functions-from-c) to call a function named `_step`.
Here's one way straightforward way to implement the function:

```rust
    fn _step(r: &mut [f32], d: &[f32], n: usize) {
        for i in 0..n {
            for j in 0..n {
                let mut v = std::f32::INFINITY;
                for k in 0..n {
                    let x = d[n*i + k];
                    let y = d[n*k + j];
                    let z = x + y;
                    v = if z < v { z } else { v };
                }
                r[n*i + j] = v;
            }
        };
    }
```

`TODO this section`
This is almost identical to the reference solution in C++.
Everything works well until we wish to run it in parallel.
The problem is that Rust allows only moving mutable references, not sharing.
This means that we cannot e.g. wrap each iteration of the second for-loop, indexed by `j`, into closures and execute each in independent threads, because we can move `r` into only one of those threads.

Here is another approach: we create a closure which captures immutable state (`d`) by reference from the enclosing scope, and accepts mutable state (`r`) only as a parameter:
```rust
    fn _step(r: &mut [f32], d: &[f32], n: usize) {
        let _step_row = |(i, row): (usize, &mut [f32])| {
            for j in 0..n {
                let mut v = std::f32::INFINITY;
                for k in 0..n {
                    let x = d[n*i + k];
                    let y = d[n*k + j];
                    let z = x + y;
                    v = if z < v { z } else { v };
                }
                row[j] = v;
            }
        };
        r.chunks_mut(n).enumerate().for_each(_step_row);
    }
```
All heavy lifting is implemented inside the closure, which takes as parameter a tuple `(i, row)`, where `i` is a slice index and `row` is a mutable slice into some memory block containing single precision floating point numbers.
In order to use this function on the result slice `r`, we must first partition `r` into rows of length `n`.
Rust slices have a builtin method [`chunks_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_mut), which will divide the slice into non-overlapping, mutable subslices of a given length.

All that remains is to apply `_step_row` on each row (chunk) of `r`:

```rust
    r.chunks_mut(n).enumerate().for_each(_step_row);
```
Breaking that down:
* `r.chunks_mut(n)`: partition `r` into `n` rows, each of size `n`
* `.enumerate()`: transform the row iterator into an iterator of `(i, row)` tuples, where each `i` is the index of each row
* `.for_each(_step_row)`: apply `_step_each` on each `(i, row)` tuple

If the indexing scheme seems confusing, consider the last line of the `_step_row` closure:
```rust
    row[j] = v;
```
If we were to iterate over `r` using two nested for loops of length `n` (as in the [C++ reference solution](http://ppc.cs.aalto.fi/ch2/v0/) for v0), then for all `i` and `j`, `r[n*i + j]` would refer to the same memory location as `row[j]`, for every tuple `(i, row)` passed to `_step_row`.

## Parallel version

Parallelizing the above solution is easy, we simply replace the serial iterator `chunks_mut` with a Rayon function [`par_chunks_mut`](https://docs.rs/rayon/1.0.2/rayon/slice/trait.ParallelSliceMut.html#method.par_chunks_mut), which will create chunks as parallel slices, apply `_step_row` to each parallel slice, and join all threads:
```rust
    r.par_chunks_mut(n).enumerate().for_each(_step_row);
```

### Disabling parallel execution support using conditional compilation

Similar to C preprocessor macros, Rust supports compile time syntax modifications by using [attributes](https://doc.rust-lang.org/reference/attributes.html), which may be used to detect compilation features.
The [build script](/build.py) for this project supports the flag `--no-multi-thread`, which will remove all OpenMP-pragmas from C++ implementations and all Rayon functionality from Rust implementations.
This allows us to easily choose between compiling a serial or parallel program:
```rust
    #[cfg(not(feature = "no-multi-thread"))]
    r.par_chunks_mut(n).enumerate().for_each(_step_row);
    #[cfg(feature = "no-multi-thread")]
    r.chunks_mut(n).enumerate().for_each(_step_row);
```
